+++
title = "Deployment"
menuTitle = "Deployment"
weight = 50
chapter = true
+++

In this section, we'll go over some features for deployment of SageMaker ML models in a cost-effective manner. We'll use Inference Pipelines to chain several models together and apply a Batch Transformation to generate inference over a bulk of data. We'll deploy an endpoint using Elastic Inference to reduce costs and optimize resource usage without needing to change any code.