+++
title = "Processing with Spark"
menuTitle = "Processing with Spark"
weight = 10
+++

In the first example we'll see how to create a docker image containing Spark, start a Spark cluster based on it (and managed by SageMaker), run the transformation script (generated inside the notebook itself) and use the results to train an XGBoost model. The provided code does all the Spark cluster configuration, and it can be reused by any job you may need.

{{% notice info %}}
Configuring a Spark cluster is an advanced and specialized skill. The code provided is a convenience to start and run your own clusters as needed, and doesn't need to be modified unless special Spark features are needed. It is also possible to simply provide a script that submits code to AWS Glue or EMR, depending on your environment.
{{% /notice %}}

To start the lab: on your notebook instance, click on the SageMaker icon on the left bar to open the list of examples. 
![SageMaker Examples](/images/other_topics/sagemaker_examples.png)

Then scroll down to the ***SageMaker Processing > feature_transformation_with_sagemaker_processing.ipynb*** and click on it. It's close to the bottom of the sidebar.
![Processing SparkML](/images/ml_pipelines/processing_sparkml_example.png)

SageMaker will open a preview of the example on a new tab. Click on the **Create a Copy** button to get a complete working copy of the example.
![Create a Copy](/images/other_topics/example_create_copy.png) 

Confirm the prompt to create the folder with the notebook and any additional files.
![Confirm create copy](/images/other_topics/confirm_example_copy.png).

Proceed to read and execute the example at your own pace.