<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SageMaker Deep Dive for Adidas on SageMaker Deep Dive</title>
    <link>/</link>
    <description>Recent content in SageMaker Deep Dive for Adidas on SageMaker Deep Dive</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Mon, 28 Oct 2019 21:11:22 -0700</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Workflow</title>
      <link>/02.-training/03.-sagemaker_dist_training/workflow.html</link>
      <pubDate>Mon, 28 Oct 2019 12:59:15 -0700</pubDate>
      
      <guid>/02.-training/03.-sagemaker_dist_training/workflow.html</guid>
      <description>Navigate to sagemaker-workshop-202006 &amp;gt; labs &amp;gt; 01. Training &amp;gt; 01. Distributed Training &amp;gt; part-2-sagemaker You should see the following files:
part-2-sagemaker/ ├── cifar10-sagemaker-distributed.ipynb └── code ├── cifar10-multi-gpu-horovod-sagemaker.py └── model_def.py    Files/directories Description     cifar10-sagemaker-distributed.ipynb This jupyter notebook contains code to define and kick off a SageMaker training job   code This directory contains the training scrip and other training script dependencies    SageMaker is a fully-managed service, which means when you kick off a training job using the SageMaker SDK in the cifar10-sagemaker-distributed.</description>
    </item>
    
    <item>
      <title>Challenges with scaling machine learning</title>
      <link>/01.-intro/01.-challenges.html</link>
      <pubDate>Mon, 28 Oct 2019 20:56:39 -0700</pubDate>
      
      <guid>/01.-intro/01.-challenges.html</guid>
      <description>There are two key challenges associated with scaling machine learning computation.
 Development setup on a single computer or instance doesn&amp;rsquo;t translate well when deploying to cluster Managing infrastructure is challenging for machine learning researchers, data scientists and developer without IT/ops background  </description>
    </item>
    
    <item>
      <title>Updates required to run on SageMaker</title>
      <link>/02.-training/03.-sagemaker_dist_training/training_scrip_updates.html</link>
      <pubDate>Mon, 28 Oct 2019 13:42:13 -0700</pubDate>
      
      <guid>/02.-training/03.-sagemaker_dist_training/training_scrip_updates.html</guid>
      <description>There are few minor changes required to run a training script on Amazon Sagemaker
SageMaker hyperparameters  SageMaker passes hyperparameters to the training scripts as commandline arguments. Your script must be able to parse these arguments.  SageMaker environment variables  SageMaker makes several environment variables available inside the container that a training script can take advantage of for finding location of the training dataset, number of GPU in the instance, dataset channels and others.</description>
    </item>
    
    <item>
      <title>Addressing scaling challenges - software dependencies</title>
      <link>/01.-intro/02.-addressing_challenges.html</link>
      <pubDate>Mon, 28 Oct 2019 21:02:29 -0700</pubDate>
      
      <guid>/01.-intro/02.-addressing_challenges.html</guid>
      <description> Software dependencies Containers provide consistent, lightweight and portable environment that includes not just the training code but also dependencies and configuration. Simply package up your code and push it to a container registry. The container image can then be pulled into a cluster and run at scale. </description>
    </item>
    
    <item>
      <title>SageMaker distributed training</title>
      <link>/02.-training/03.-sagemaker_dist_training/sagemaker_training.html</link>
      <pubDate>Mon, 28 Oct 2019 13:17:44 -0700</pubDate>
      
      <guid>/02.-training/03.-sagemaker_dist_training/sagemaker_training.html</guid>
      <description>Open cifar10-sagemaker-distributed.ipynb and run through the cells. The following notebook is located at: distributed-training-workshop &amp;gt; notebooks &amp;gt; part-2-sagemaker &amp;gt; cifar10-sagemaker-distributed.ipynb
Stop: Do this section on JupyterLab. Below is a copy of the jupyter notebook for reference.  Distributed training with Amazon SageMaker In this notebook we use the SageMaker Python SDK to setup and run a distributed training job. SageMaker makes it easy to train models across a cluster containing a large number of machines, without having to explicitly manage those resources.</description>
    </item>
    
    <item>
      <title>Addressing scaling challenges - Infrastructure management</title>
      <link>/01.-intro/03.-addressing_challenges-1.html</link>
      <pubDate>Mon, 28 Oct 2019 21:07:47 -0700</pubDate>
      
      <guid>/01.-intro/03.-addressing_challenges-1.html</guid>
      <description> Infrastructure management </description>
    </item>
    
    <item>
      <title>Distributed training approaches</title>
      <link>/01.-intro/04.-horovod.html</link>
      <pubDate>Mon, 28 Oct 2019 21:11:22 -0700</pubDate>
      
      <guid>/01.-intro/04.-horovod.html</guid>
      <description>Horovod Horovod documentation
Horovod is based on the MPI concepts: size, rank, local rank, allreduce, allgather, and broadcast.
 Library for distributed deep learning with support for multiple frameworks including TensorFlow Separates infrastructure from ML engineers Uses ring-allreduce and uses Message Passing Interface (MPI) popular in the HPC community Infrastructure services such as Amazon SageMaker and Amazon EKS provides container and MPI environment   Forward pass on each device Backward pass compute gradients ”All reduce” (average and broadcast) gradients across devices Update local variables with “all reduced” gradients  Horovod will run the same copy of the script on all hosts/servers/nodes/instances</description>
    </item>
    
    <item>
      <title>Launch a SageMaker notebook instance</title>
      <link>/02.-training/01.-setup/sm_jupyter_instance.html</link>
      <pubDate>Sun, 27 Oct 2019 22:39:43 -0700</pubDate>
      
      <guid>/02.-training/01.-setup/sm_jupyter_instance.html</guid>
      <description>Note: In this workshop, we&amp;rsquo;ll be using an Amazon SageMaker notebook instance for simplicity and convenience. You can use any local client to perform steps detailed in this and subsequent sections. You&amp;rsquo;ll just need to make sure you have the right privileges to access AWS services such as SageMaker, S3, ECR and others from your client. You&amp;rsquo;ll also need to install AWS Command Line Interface (AWS CLI), python, boto3 and SageMaker SDK.</description>
    </item>
    
    <item>
      <title>Problem statement</title>
      <link>/02.-training/02.-single_instance_training/problem_setup.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02.-training/02.-single_instance_training/problem_setup.html</guid>
      <description>Converting a single CPU/GPU training script to a multi-node/distributed compatible training script Frameworks: This workshop currently uses TensorFlow 1.14, Keras and Horovod 0.18.
Dataset: The CIFAR-10 consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). CIFAR-10 dataset includes:
 40,000 images for training 10,000 images for validation 10,000 images for test  Here are the classes in the dataset, as well as 10 random images from each: Note: Although the dataset is small and this is a simpler problem, all the steps we&amp;rsquo;ll take can easily be applied to large datasets that don&amp;rsquo;t fit in memory.</description>
    </item>
    
    <item>
      <title>Processing with Spark</title>
      <link>/04.-ml-pipelines/01.-processing-jobs/01.-preprocess_spark.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04.-ml-pipelines/01.-processing-jobs/01.-preprocess_spark.html</guid>
      <description>In the first example we&amp;rsquo;ll see how to create a docker image containing Spark, start a Spark cluster based on it (and managed by SageMaker), run the transformation script (generated inside the notebook itself) and use the results to train an XGBoost model. The provided code does all the Spark cluster configuration, and it can be reused by any job you may need.
Configuring a Spark cluster is an advanced and specialized skill.</description>
    </item>
    
    <item>
      <title>Download the workshop content</title>
      <link>/02.-training/01.-setup/download_workshop.html</link>
      <pubDate>Mon, 28 Oct 2019 00:14:06 -0700</pubDate>
      
      <guid>/02.-training/01.-setup/download_workshop.html</guid>
      <description>Launch JupyterLab client and clone the workshop repository  Your notebook instance should now be ready. Click JupyterLab to launch your client.  Click File &amp;gt; New &amp;gt; Terminal to launch terminal in your JupyterLab instance.  Download the workshop code and notebooks. Enter bash (optional), change directory to ~/SageMaker, clone the repository
bash cd ~/SageMaker git clone https://github.com/bobbruno/sagemaker-workshop-202006.git Fix the link above to a repo of my creation</description>
    </item>
    
    <item>
      <title>Prepare training dataset</title>
      <link>/02.-training/02.-single_instance_training/prepare_dataset.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02.-training/02.-single_instance_training/prepare_dataset.html</guid>
      <description>Download the CIFAR10 dataset and upload it to Amazon S3 On a terminal window in JupyterLab client, navigate to the notebook directory
cd ~/SageMaker/sagemaker-workshop-202006/notebooks/ Activate the TensorFlow conda environment
source activate tensorflow_p36 Before running the command above, you may have to run &amp;ldquo;. /home/ec2-user/anaconda3/etc/profile.d/conda.sh&amp;rdquo;.
 Download CIFAR10 dataset and convert it to TFRecords format
python generate_cifar10_tfrecords.py --data-dir dataset Confirm that the dataset was downloaded successfully. Run:
sudo yum install tree -y tree dataset You should see the following output</description>
    </item>
    
    <item>
      <title>Processing with Dask</title>
      <link>/04.-ml-pipelines/01.-processing-jobs/02.-preprocess_dask.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/04.-ml-pipelines/01.-processing-jobs/02.-preprocess_dask.html</guid>
      <description>The second example shows how to create a docker image containing Dask and run a transformation script using it on a cluster managed by SageMaker. The results will be used to train an XGBoost model. The provided code does all the configuration, and it can be reused by any job you may need.
Dask is a sophisticated processing framework which, among other interfaces, provides functionality similar to Pandas. The script provided uses a combination of Pandas and Dask processing, but any Dask interface is possible.</description>
    </item>
    
    <item>
      <title>Getting familiar with a single instance training script</title>
      <link>/02.-training/02.-single_instance_training/single_instance_script.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02.-training/02.-single_instance_training/single_instance_script.html</guid>
      <description>Single CPU/GPU training on the local instance 
In this section you&amp;rsquo;ll get familiar with the training script we&amp;rsquo;ll be converting for distributed training in the next notebook.
Open cifar10-single-instance.ipynb and run through the cells. The following notebook is located at: sagemaker-workshop-202006 &amp;gt; labs &amp;gt; 01. Training &amp;gt; 01. Distributed Training &amp;gt; part-1-horovod
Stop: Do this section on JupyterLab. Below is a copy of the jupyter notebook for reference.  Below is a copy of the Jupyter notebook cifar10-single-instance.</description>
    </item>
    
    <item>
      <title>Converting the script for Horovod API distributed training</title>
      <link>/02.-training/02.-single_instance_training/distributed_training_script.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/02.-training/02.-single_instance_training/distributed_training_script.html</guid>
      <description>Exercise 1: Convert training script to use horovod 
In this section you&amp;rsquo;ll update the training script with horovod API for run distributed training.
Open cifar10-distributed.ipynb and run through the cells. The following notebook is located at: sagemaker-workshop-202006 &amp;gt; labs &amp;gt; 01. Training &amp;gt; 01. Distributed Training &amp;gt; part-1-horovod
Stop: Do this section on JupyterLab. Below is a copy of the jupyter notebook for reference. Open cifar10-distributed.ipynb and run these cells.</description>
    </item>
    
    <item>
      <title>Monitoring training progress</title>
      <link>/02.-training/03.-sagemaker_dist_training/monitoring_results.html</link>
      <pubDate>Mon, 28 Oct 2019 13:54:27 -0700</pubDate>
      
      <guid>/02.-training/03.-sagemaker_dist_training/monitoring_results.html</guid>
      <description>Monitoring training progress using tensorboard The cifar10-sagemaker-distributed.ipynb notebook will automatically start a tensorboard server for you when your run the following cell. Tensorboard is running locally on your Jupyter notebook instance, but reading the events from the Amazon S3 bucket we used to save the events using the keras callback.
!S3_REGION=us-east-1 tensorboard --logdir s3://{bucket_name}/tensorboard_logs/ Navigate to https://adidas202006.notebook.us-east-1.sagemaker.aws/proxy/6006/
Replace adidas202006 with the name of your Jupyter notebook instance. Monitoring training job status on the AWS SageMaker console Navigate to AWS management console &amp;gt; SageMaker console to see a full list of training jobs and their status.</description>
    </item>
    
  </channel>
</rss>